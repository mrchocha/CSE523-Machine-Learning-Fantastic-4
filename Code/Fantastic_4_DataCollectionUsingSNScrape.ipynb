{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fantastic-4_DataCollectionUsingSNScrape.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wRDx_hhWWeNz",
        "msNkOX11UO3Z",
        "2K0gTD8ugbLU",
        "5qqit9hNghWl",
        "gYE7D21DU0HM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrchocha/CSE523-Machine-Learning-Fantastic-4/blob/main/Fantastic_4_DataCollectionUsingSNScrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRDx_hhWWeNz"
      },
      "source": [
        "#Data collection for by days for various DIJA indices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msNkOX11UO3Z"
      },
      "source": [
        "##Importing SnScrape and other libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hyY7G_WUEHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77985278-52da-4c0d-9e0f-4b99bc33348a"
      },
      "source": [
        "pip install snscrape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting snscrape\n",
            "  Downloading https://files.pythonhosted.org/packages/81/dd/4a4ec9eedd8cc85ced7c5a6a23853965195203aec825ef3f7778a0c3b69e/snscrape-0.3.4-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.2.6)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fXt1jYHUwDy"
      },
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from google.colab import files\n",
        "import os, shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K0gTD8ugbLU"
      },
      "source": [
        "## Functions for NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpKHXNOE3CpQ"
      },
      "source": [
        "# Create a function to compute negative (-1), neutral (0) and positive (+1) analysis\n",
        "def getAnalysis(score):\n",
        "  if score < 0:\n",
        "    return 'Negative'\n",
        "  elif score == 0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        "\n",
        "def cleanText(text):\n",
        " text = re.sub('@[A-Za-z0â€“9]+', '', text) #Removing @mentions\n",
        " text = re.sub('#', '', text) # Removing '#' hash tag\n",
        " text = re.sub('RT[\\s]+', '', text) # Removing RT\n",
        " text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlink\n",
        " \n",
        " return text\n",
        "\n",
        "# Create a function to get the subjectivity\n",
        "def getSubjectivity(text):\n",
        "   return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "# Create a function to get the polarity\n",
        "def getPolarity(text):\n",
        "   return  TextBlob(text).sentiment.polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLPHQKvkX_pc"
      },
      "source": [
        "#Fully Automated Code for Data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qqit9hNghWl"
      },
      "source": [
        "##Funciton for automating this data collection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbGtn462gmDa"
      },
      "source": [
        "year = 2010\n",
        "#----------------------------change here----------------------------\n",
        "month = 6\n",
        "\n",
        "def createFromDate(day):\n",
        "  ans = \"\"+str(year)+\"-\"\n",
        "  ans += str(month).zfill(2)+\"-\"\n",
        "  ans += str(day).zfill(2)\n",
        "  return ans\n",
        "\n",
        "def createEndDate(day):\n",
        "  ans = \"\"+str(year)+\"-\"\n",
        "  ans += str(month).zfill(2)+\"-\"\n",
        "  ans += str(day).zfill(2)\n",
        "  return ans\n",
        "\n",
        "def monthGen():\n",
        "  months = ['Jan', 'Feb', 'March', 'April', 'May', 'June', 'July', 'August', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "  return months[month-1]\n",
        "\n",
        "def createFileName(company, day):\n",
        "  ans = company+\"_\"\n",
        "  ans += str(day).zfill(2)+\"_\"\n",
        "  ans += monthGen()+\"_\"\n",
        "  ans += str(year)\n",
        "  ans += \".csv\"\n",
        "  return ans\n",
        "\n",
        "def createQuery(company, day):\n",
        "  ans = \"$\"\n",
        "  ans += company\n",
        "  ans += \" since:\"\n",
        "  ans += createFromDate(day)\n",
        "  ans += \" until:\"\n",
        "  ans += createEndDate(day+1)\n",
        "  return ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYE7D21DU0HM"
      },
      "source": [
        "## Firing Query for only one Day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNeMX64sdJJT"
      },
      "source": [
        "maxTweets = 10000\n",
        "tweets = []\n",
        "companies = [\"AMZN\", \"AAPL\", \"T\", \"DELL\", \"EBAY\", \"GOOG\", \"IBM\", \"INTC\", \"MSFT\", \"ORCL\", \"SSNLF\", \"SAP\", \"YHOO\"]\n",
        "\n",
        "for com in companies:\n",
        "  #----------------------------change here----------------------------\n",
        "  q = \"$\"+com+\" since:2010-06-30 until:2010-07-01\"\n",
        "  for i,tweet in enumerate(sntwitter.TwitterSearchScraper(q).get_items()):\n",
        "      if i>maxTweets:\n",
        "          break\n",
        "      tweets.append([tweet.url, tweet.date, tweet.id, tweet.content])\n",
        "\n",
        "  # Making a dataframe of the data we got from the SNScrape.\n",
        "  df_tweets = pd.DataFrame(tweets, columns=['Url', 'Datetime', 'Tweet_Id', 'Text'])\n",
        "\n",
        "  # Cleaning the 'text' field from the dataframe.\n",
        "  # Creating 2 columns of Subjectivity and Polarity.\n",
        "  # Creating a column having Labels Pos, Neg, Nut.\n",
        "  df_tweets['Text'] = df_tweets['Text'].apply(cleanText)\n",
        "  df_tweets['Subjectivity'] = df_tweets['Text'].apply(getSubjectivity)\n",
        "  df_tweets['Polarity'] = df_tweets['Text'].apply(getPolarity)\n",
        "  df_tweets['Label'] = df_tweets['Polarity'].apply(getAnalysis)\n",
        "\n",
        "  #----------------------------change here----------------------------\n",
        "  df_tweets.to_csv(createFileName(com, 30))\n",
        "  # files.download(fname)\n",
        "  print(createFileName(com, 31))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9f_Qrns9o9u"
      },
      "source": [
        "##Automating the dowanload of data of all days."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymg5PlMA-xFg"
      },
      "source": [
        "maxTweets = 10000\n",
        "tweets = []\n",
        "cnt = 0\n",
        "\n",
        "companies = [\"AMZN\", \"AAPL\", \"T\", \"DELL\", \"EBAY\", \"GOOG\", \"IBM\", \"INTC\", \"MSFT\", \"ORCL\", \"SSNLF\", \"SAP\", \"YHOO\"]\n",
        "\n",
        "for com in companies:\n",
        "\n",
        "  #----------------------------change here----------------------------\n",
        "  for day in range(1,30):\n",
        "\n",
        "    tweets = []\n",
        "    q = createQuery(com, day)\n",
        "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(q).get_items()):\n",
        "      if i>maxTweets:\n",
        "          break\n",
        "      tweets.append([tweet.url, tweet.date, tweet.id, tweet.content])\n",
        "    \n",
        "    df_tweets = pd.DataFrame(tweets, columns=['Url', 'Datetime', 'Tweet_Id', 'Text'])\n",
        "\n",
        "    df_tweets['Text'] = df_tweets['Text'].apply(cleanText)\n",
        "    df_tweets['Subjectivity'] = df_tweets['Text'].apply(getSubjectivity)\n",
        "    df_tweets['Polarity'] = df_tweets['Text'].apply(getPolarity)\n",
        "    df_tweets['Label'] = df_tweets['Polarity'].apply(getAnalysis)\n",
        "\n",
        "    df_tweets.to_csv(createFileName(com, day))\n",
        "    print(cnt, \". \",createFileName(com, day), \" successfully created.\")\n",
        "    cnt += 1\n",
        "    # files.download(createFileName(com, day))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1mg32p4ELC1"
      },
      "source": [
        "path = './'+monthGen()+\"_\"+str(year)\n",
        "os.mkdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNj0pB67Gdfr",
        "outputId": "dd3f5b8d-a758-45e9-da7e-be9facb65cb7"
      },
      "source": [
        "src_fname = \"./\"+monthGen()+\"_\"+str(year)\n",
        "down_fname = src_fname+\".zip\"\n",
        "\n",
        "print(down_fname)\n",
        "print(src_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./June_2010.zip\n",
            "./June_2010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2P6gvguGgvk"
      },
      "source": [
        "companies = [\"AMZN\", \"AAPL\", \"T\", \"DELL\", \"EBAY\", \"GOOG\", \"IBM\", \"INTC\", \"MSFT\", \"ORCL\", \"SSNLF\", \"SAP\", \"YHOO\"]\n",
        "\n",
        "for com in companies:\n",
        "  #----------------------------change here----------------------------\n",
        "  for day in range(1,31):\n",
        "    shutil.move(createFileName(com, day), src_fname)\n",
        "    print(createFileName(com, day), \" moved successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ejy4A99-eGiq",
        "outputId": "c623274b-101b-4e92-a390-4106dba05d10"
      },
      "source": [
        "shutil.make_archive(src_fname, 'zip', src_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/June_2010.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkUYeg4wHHZQ"
      },
      "source": [
        "files.download(down_fname)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
